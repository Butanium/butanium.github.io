---
title: "Satisficing Reinforcement Learning"
collection: research
permalink: /research/2023-09-10-satisficing-rl
excerpt: 'Inspired by satisficing, we introduce a novel concept of non-maximizing agents, א-aspiring agents, whose goal is to achieve an expected gain of א. We derive aspiration-based algorithms from Q-learning and DQN.'
date: 2023-09-10
authors: "Clément Dumas*, Jobst Heitzig*"
posturl: https://www.lesswrong.com/posts/Z9P2m462wQ4qmH6uo/aspiration-based-q-learning
paperurl: /files/satisficing-rl.pdf
---
This work was conducted during my final year bachelor's internship at the PIK (Potsdam Institute for Climate Impact Research) under the supervision of [Jobst Heitzig](https://www.pik-potsdam.de/members/heitzig).

There are three outputs from this project:

- A [blog post](https://www.lesswrong.com/posts/Z9P2m462wQ4qmH6uo/aspiration-based-q-learning) on LessWrong, crossposted on the [Alignment Forum](https://www.alignmentforum.org/posts/Z9P2m462wQ4qmH6uo/aspiration-based-q-learning), presenting the main ideas and the results of the project.
- An [internship academic report](/files/satisficing-rl.pdf) providing a detailed presentation of the project, following the structure of a research paper.
- A [GitHub repository](https://github.com/pik-gane/stable-baselines3-contrib-satisfia) that implements the algorithms presented in the report using the [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) framework.